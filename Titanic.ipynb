{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train_df = pd.read_csv(\"train.csv\").replace(\"male\",0).replace(\"female\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Survived       False\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age             True\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare           False\n",
       "Cabin           True\n",
       "Embarked        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欠損値の確認\n",
    "train_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 欠損値を補完\n",
    "train_df[\"Age\"].fillna(train_df.Age.median(), inplace=True)\n",
    "train_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\n",
    "train_df2 = train_df.drop([\"Name\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータに分割\n",
    "data = train_df2.values\n",
    "train_df = data[:round(len(data)*0.8),:]\n",
    "test_df = data[round(len(data)*0.8):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_df[:,2:]\n",
    "y_train = train_df[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline作成\n",
    "#estimators = [('classifier', RandomForestClassifier())]\n",
    "estimators = [('pca', PCA()),\n",
    "              ('svm', svm.SVC())]\n",
    "pl = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"pca__n_components\" : range(2, 6),\n",
    "              \"svm__kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "              'svm__C': np.logspace(0, 2, 10).tolist(),\n",
    "              \"svm__gamma\": np.logspace(-3, 0, 10).tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pl, parameters, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x108f25390, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/yasu/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/yasu/.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x108f25390, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/yasu/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/yasu/.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 23, 17, 27, 46, 387105, tzinfo=datetime.timezone.utc), 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'session': '1A787CD361264250A5EA190FACBEA43E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1A787CD361264250A5EA190FACBEA43E']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 23, 17, 27, 46, 387105, tzinfo=datetime.timezone.utc), 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'session': '1A787CD361264250A5EA190FACBEA43E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1A787CD361264250A5EA190FACBEA43E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 23, 17, 27, 46, 387105, tzinfo=datetime.timezone.utc), 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'session': '1A787CD361264250A5EA190FACBEA43E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-20-bdba31e0021c>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 11605b1d0, execution_..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x11618ded0, file \"<ipython-input-20-bdba31e0021c>\", line 10>\n        result = <ExecutionResult object at 11605b1d0, execution_..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x11618ded0, file \"<ipython-input-20-bdba31e0021c>\", line 10>, result=<ExecutionResult object at 11605b1d0, execution_..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x11618ded0, file \"<ipython-input-20-bdba31e0021c>\", line 10>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport matplotlib.pyplot as ...\\nfrom sklearn.model_selection import GridSearchCV', '# 学習データの読み込み\\ntrain_df = pd.read_csv(\"train.csv\").replace(\"male\",0).replace(\"female\",1)', '# 欠損値の確認\\ntrain_df.isnull().any()', '# 欠損値を補完\\ntrain_df[\"Age\"].fillna(train_df.Age.med..., \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"], axis=1)', '# 学習データとテストデータに分割\\ndata = train_df2.values\\ntrain_...)*0.8),:]\\ntest_df = data[round(len(data)*0.8):,:]', 'x_train = train_df[:,2:]\\ny_train = train_df[:,1]', \"# Pipeline作成\\nestimators = [('classifier', RandomForestClassifier())]\\npl = Pipeline(estimators)\", 'parameters = {\"max_depth\": [3, None],\\n          ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\"max_depth\": [3, None],\\n          ...parameters, n_jobs=-1)\\n#clf.fit(x_train, y_train)', 'len(x_train)', 'len(y_train)', 'parameters = {\"max_depth\": [3, None],\\n          ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {#\"max_depth\": [3, None],\\n         ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": [3, None]\\n      ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    #\"max_depth\": [3, None]\\n    \"... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": None\\n    #\"max_f... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": None\\n    #\"max_f... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": 2\\n    #\"max_feat... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": 2,\\n    \"max_feat... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', ...], 'Out': {3: PassengerId    False\nSurvived       False\nPclass...n           True\nEmbarked        True\ndtype: bool, 10: 713, 11: 713}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, '_': 713, '_10': 713, '_11': 713, '_3': PassengerId    False\nSurvived       False\nPclass...n           True\nEmbarked        True\ndtype: bool, '__': 713, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport matplotlib.pyplot as ...\\nfrom sklearn.model_selection import GridSearchCV', '# 学習データの読み込み\\ntrain_df = pd.read_csv(\"train.csv\").replace(\"male\",0).replace(\"female\",1)', '# 欠損値の確認\\ntrain_df.isnull().any()', '# 欠損値を補完\\ntrain_df[\"Age\"].fillna(train_df.Age.med..., \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"], axis=1)', '# 学習データとテストデータに分割\\ndata = train_df2.values\\ntrain_...)*0.8),:]\\ntest_df = data[round(len(data)*0.8):,:]', 'x_train = train_df[:,2:]\\ny_train = train_df[:,1]', \"# Pipeline作成\\nestimators = [('classifier', RandomForestClassifier())]\\npl = Pipeline(estimators)\", 'parameters = {\"max_depth\": [3, None],\\n          ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\"max_depth\": [3, None],\\n          ...parameters, n_jobs=-1)\\n#clf.fit(x_train, y_train)', 'len(x_train)', 'len(y_train)', 'parameters = {\"max_depth\": [3, None],\\n          ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {#\"max_depth\": [3, None],\\n         ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": [3, None]\\n      ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    #\"max_depth\": [3, None]\\n    \"... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": None\\n    #\"max_f... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": None\\n    #\"max_f... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": 2\\n    #\"max_feat... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": 2,\\n    \"max_feat... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', ...], 'Out': {3: PassengerId    False\nSurvived       False\nPclass...n           True\nEmbarked        True\ndtype: bool, 10: 713, 11: 713}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, '_': 713, '_10': 713, '_11': 713, '_3': PassengerId    False\nSurvived       False\nPclass...n           True\nEmbarked        True\ndtype: bool, '__': 713, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Volumes/SD Card/Workspace/Kaggle/Titanic/<ipython-input-20-bdba31e0021c> in <module>()\n      5           #\"min_samples_leaf\": [1, 3, 10],\n      6           #\"criterion\": [\"gini\", \"entropy\"]}\n      7     }\n      8 \n      9 clf = GridSearchCV(pl, parameters, n_jobs=-1)\n---> 10 clf.fit(x_train, y_train)\n     11 \n     12 \n     13 \n     14 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), y=array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=0)>\n        X = array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]])\n        y = array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.])\n        groups = None\n        self.param_grid = {'max_depth': [2, 4], 'max_features': [1, 3, 10]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), y=array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Oct 24 02:27:46 2017\nPID: 2223                     Python 3.6.1: /Users/yasu/anaconda/bin/python\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), <function _passthrough_scorer>, array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), 0, {'max_depth': 2, 'max_features': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), <function _passthrough_scorer>, array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), 0, {'max_depth': 2, 'max_features': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), X=array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), y=array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), scorer=<function _passthrough_scorer>, train=array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), verbose=0, parameters={'max_depth': 2, 'max_features': 1}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...one,\n            verbose=0, warm_start=False))])>\n        parameters = {'max_depth': 2, 'max_features': 1}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), **kwargs={'max_depth': 2, 'max_features': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...one,\n            verbose=0, warm_start=False))])>\n        kwargs = {'max_depth': 2, 'max_features': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), steps_attr='steps', **params={'max_depth': 2, 'max_features': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...one,\n            verbose=0, warm_start=False))])>\n        params = {'max_depth': 2, 'max_features': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), **params={'max_depth': 2, 'max_features': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 227, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 180, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 69, in _set_params\n    super(_BasePipeline, self).set_params(**params)\n  File \"/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/base.py\", line 291, in set_params\n    (key, self.__class__.__name__))\nValueError: Invalid parameter max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/yasu/anaconda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Oct 24 02:27:46 2017\nPID: 2223                     Python 3.6.1: /Users/yasu/anaconda/bin/python\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), <function _passthrough_scorer>, array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), 0, {'max_depth': 2, 'max_features': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), <function _passthrough_scorer>, array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), 0, {'max_depth': 2, 'max_features': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), X=array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), y=array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), scorer=<function _passthrough_scorer>, train=array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), verbose=0, parameters={'max_depth': 2, 'max_features': 1}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...one,\n            verbose=0, warm_start=False))])>\n        parameters = {'max_depth': 2, 'max_features': 1}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), **kwargs={'max_depth': 2, 'max_features': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...one,\n            verbose=0, warm_start=False))])>\n        kwargs = {'max_depth': 2, 'max_features': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), steps_attr='steps', **params={'max_depth': 2, 'max_features': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...one,\n            verbose=0, warm_start=False))])>\n        params = {'max_depth': 2, 'max_features': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), **params={'max_depth': 2, 'max_features': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yasu/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Oct 24 02:27:46 2017\nPID: 2223                     Python 3.6.1: /Users/yasu/anaconda/bin/python\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), <function _passthrough_scorer>, array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), 0, {'max_depth': 2, 'max_features': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), <function _passthrough_scorer>, array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), 0, {'max_depth': 2, 'max_features': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), X=array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), y=array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), scorer=<function _passthrough_scorer>, train=array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), verbose=0, parameters={'max_depth': 2, 'max_features': 1}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...one,\n            verbose=0, warm_start=False))])>\n        parameters = {'max_depth': 2, 'max_features': 1}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), **kwargs={'max_depth': 2, 'max_features': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...one,\n            verbose=0, warm_start=False))])>\n        kwargs = {'max_depth': 2, 'max_features': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), steps_attr='steps', **params={'max_depth': 2, 'max_features': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...one,\n            verbose=0, warm_start=False))])>\n        params = {'max_depth': 2, 'max_features': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), **params={'max_depth': 2, 'max_features': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bdba31e0021c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x108f25390, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/yasu/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/yasu/.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x108f25390, file \"/Use...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/Users/yasu/anaconda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/Users/yasu/.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 23, 17, 27, 46, 387105, tzinfo=datetime.timezone.utc), 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'session': '1A787CD361264250A5EA190FACBEA43E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1A787CD361264250A5EA190FACBEA43E']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 23, 17, 27, 46, 387105, tzinfo=datetime.timezone.utc), 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'session': '1A787CD361264250A5EA190FACBEA43E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1A787CD361264250A5EA190FACBEA43E'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 23, 17, 27, 46, 387105, tzinfo=datetime.timezone.utc), 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'session': '1A787CD361264250A5EA190FACBEA43E', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'CEDBD6D035E84DAA8E6ADB664689DA3F', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='parameters = {\\n    \"max_depth\": [2, 4],\\n    \"max... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-20-bdba31e0021c>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 11605b1d0, execution_..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x11618ded0, file \"<ipython-input-20-bdba31e0021c>\", line 10>\n        result = <ExecutionResult object at 11605b1d0, execution_..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x11618ded0, file \"<ipython-input-20-bdba31e0021c>\", line 10>, result=<ExecutionResult object at 11605b1d0, execution_..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x11618ded0, file \"<ipython-input-20-bdba31e0021c>\", line 10>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport matplotlib.pyplot as ...\\nfrom sklearn.model_selection import GridSearchCV', '# 学習データの読み込み\\ntrain_df = pd.read_csv(\"train.csv\").replace(\"male\",0).replace(\"female\",1)', '# 欠損値の確認\\ntrain_df.isnull().any()', '# 欠損値を補完\\ntrain_df[\"Age\"].fillna(train_df.Age.med..., \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"], axis=1)', '# 学習データとテストデータに分割\\ndata = train_df2.values\\ntrain_...)*0.8),:]\\ntest_df = data[round(len(data)*0.8):,:]', 'x_train = train_df[:,2:]\\ny_train = train_df[:,1]', \"# Pipeline作成\\nestimators = [('classifier', RandomForestClassifier())]\\npl = Pipeline(estimators)\", 'parameters = {\"max_depth\": [3, None],\\n          ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\"max_depth\": [3, None],\\n          ...parameters, n_jobs=-1)\\n#clf.fit(x_train, y_train)', 'len(x_train)', 'len(y_train)', 'parameters = {\"max_depth\": [3, None],\\n          ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {#\"max_depth\": [3, None],\\n         ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": [3, None]\\n      ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    #\"max_depth\": [3, None]\\n    \"... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": None\\n    #\"max_f... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": None\\n    #\"max_f... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": 2\\n    #\"max_feat... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": 2,\\n    \"max_feat... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', ...], 'Out': {3: PassengerId    False\nSurvived       False\nPclass...n           True\nEmbarked        True\ndtype: bool, 10: 713, 11: 713}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, '_': 713, '_10': 713, '_11': 713, '_3': PassengerId    False\nSurvived       False\nPclass...n           True\nEmbarked        True\ndtype: bool, '__': 713, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport matplotlib.pyplot as ...\\nfrom sklearn.model_selection import GridSearchCV', '# 学習データの読み込み\\ntrain_df = pd.read_csv(\"train.csv\").replace(\"male\",0).replace(\"female\",1)', '# 欠損値の確認\\ntrain_df.isnull().any()', '# 欠損値を補完\\ntrain_df[\"Age\"].fillna(train_df.Age.med..., \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"], axis=1)', '# 学習データとテストデータに分割\\ndata = train_df2.values\\ntrain_...)*0.8),:]\\ntest_df = data[round(len(data)*0.8):,:]', 'x_train = train_df[:,2:]\\ny_train = train_df[:,1]', \"# Pipeline作成\\nestimators = [('classifier', RandomForestClassifier())]\\npl = Pipeline(estimators)\", 'parameters = {\"max_depth\": [3, None],\\n          ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\"max_depth\": [3, None],\\n          ...parameters, n_jobs=-1)\\n#clf.fit(x_train, y_train)', 'len(x_train)', 'len(y_train)', 'parameters = {\"max_depth\": [3, None],\\n          ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {#\"max_depth\": [3, None],\\n         ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": [3, None]\\n      ... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    #\"max_depth\": [3, None]\\n    \"... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": None\\n    #\"max_f... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": None\\n    #\"max_f... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": 2\\n    #\"max_feat... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', 'parameters = {\\n    \"max_depth\": 2,\\n    \"max_feat... parameters, n_jobs=-1)\\nclf.fit(x_train, y_train)', ...], 'Out': {3: PassengerId    False\nSurvived       False\nPclass...n           True\nEmbarked        True\ndtype: bool, 10: 713, 11: 713}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, '_': 713, '_10': 713, '_11': 713, '_3': PassengerId    False\nSurvived       False\nPclass...n           True\nEmbarked        True\ndtype: bool, '__': 713, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Volumes/SD Card/Workspace/Kaggle/Titanic/<ipython-input-20-bdba31e0021c> in <module>()\n      5           #\"min_samples_leaf\": [1, 3, 10],\n      6           #\"criterion\": [\"gini\", \"entropy\"]}\n      7     }\n      8 \n      9 clf = GridSearchCV(pl, parameters, n_jobs=-1)\n---> 10 clf.fit(x_train, y_train)\n     11 \n     12 \n     13 \n     14 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), y=array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=0)>\n        X = array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]])\n        y = array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.])\n        groups = None\n        self.param_grid = {'max_depth': [2, 4], 'max_features': [1, 3, 10]}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), y=array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Oct 24 02:27:46 2017\nPID: 2223                     Python 3.6.1: /Users/yasu/anaconda/bin/python\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), <function _passthrough_scorer>, array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), 0, {'max_depth': 2, 'max_features': 1}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), <function _passthrough_scorer>, array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), 0, {'max_depth': 2, 'max_features': 1})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), X=array([[  3.,   0.,  22.,   2.],\n       [  1.,  ....,  28.,   1.],\n       [  1.,   0.,  48.,   2.]]), y=array([ 0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  ...0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.]), scorer=<function _passthrough_scorer>, train=array([223, 225, 227, 228, 229, 231, 232, 234, 2..., 705,\n       706, 707, 708, 709, 710, 711, 712]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 248, 255, 256, 257,\n       258, 259, 261, 267]), verbose=0, parameters={'max_depth': 2, 'max_features': 1}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    222     fit_params = fit_params if fit_params is not None else {}\n    223     fit_params = dict([(k, _index_param_value(X, v, train))\n    224                       for k, v in fit_params.items()])\n    225 \n    226     if parameters is not None:\n--> 227         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(st...one,\n            verbose=0, warm_start=False))])>\n        parameters = {'max_depth': 2, 'max_features': 1}\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), **kwargs={'max_depth': 2, 'max_features': 1})\n    175 \n    176         Returns\n    177         -------\n    178         self\n    179         \"\"\"\n--> 180         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BasePipeline._set_params of Pipel...one,\n            verbose=0, warm_start=False))])>\n        kwargs = {'max_depth': 2, 'max_features': 1}\n    181         return self\n    182 \n    183     def _validate_steps(self):\n    184         names, estimators = zip(*self.steps)\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/pipeline.py in _set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), steps_attr='steps', **params={'max_depth': 2, 'max_features': 1})\n     64         step_names, _ = zip(*getattr(self, steps_attr))\n     65         for name in list(six.iterkeys(params)):\n     66             if '__' not in name and name in step_names:\n     67                 self._replace_step(steps_attr, name, params.pop(name))\n     68         # 3. Step parameters and other initilisation arguments\n---> 69         super(_BasePipeline, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(st...one,\n            verbose=0, warm_start=False))])>\n        params = {'max_depth': 2, 'max_features': 1}\n     70         return self\n     71 \n     72     def _validate_names(self, names):\n     73         if len(set(names)) != len(names):\n\n...........................................................................\n/Users/yasu/anaconda/lib/python3.6/site-packages/sklearn/base.py in set_params(self=Pipeline(steps=[('classifier', RandomForestClass...None,\n            verbose=0, warm_start=False))]), **params={'max_depth': 2, 'max_features': 1})\n    286                 # simple objects case\n    287                 if key not in valid_params:\n    288                     raise ValueError('Invalid parameter %s for estimator %s. '\n    289                                      'Check the list of available parameters '\n    290                                      'with `estimator.get_params().keys()`.' %\n--> 291                                      (key, self.__class__.__name__))\n        key = 'max_depth'\n        self.__class__.__name__ = 'Pipeline'\n    292                 setattr(self, key, value)\n    293         return self\n    294 \n    295     def __repr__(self):\n\nValueError: Invalid parameter max_depth for estimator Pipeline. Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"max_depth\": [2, 4],\n",
    "    \"max_features\": [1, 3, 10]\n",
    "          #\"min_samples_split\": [1, 3, 10],\n",
    "          #\"min_samples_leaf\": [1, 3, 10],\n",
    "          #\"criterion\": [\"gini\", \"entropy\"]}\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(pl, parameters, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RandomForestのモデル作成\n",
    "forest = RandomForestClassifier(n_estimators = 50)\n",
    "forest = forest.fit(train_df[:,2:],train_df[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8258426966292135"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストデータで評価\n",
    "output = forest.predict(test_df[:, 2:])\n",
    "accuracy_score(output, test_df[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.034212</td>\n",
       "      <td>-0.040143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.064910</td>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.339898</td>\n",
       "      <td>0.065997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.042939</td>\n",
       "      <td>0.543351</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.081163</td>\n",
       "      <td>0.200988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.034212</td>\n",
       "      <td>-0.064910</td>\n",
       "      <td>-0.339898</td>\n",
       "      <td>-0.081163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.245619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>-0.040143</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.065997</td>\n",
       "      <td>0.200988</td>\n",
       "      <td>-0.245619</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Sex       Age  FamilySize\n",
       "PassengerId     1.000000 -0.005007 -0.035144 -0.042939  0.034212   -0.040143\n",
       "Survived       -0.005007  1.000000 -0.338481  0.543351 -0.064910    0.016639\n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.131900 -0.339898    0.065997\n",
       "Sex            -0.042939  0.543351 -0.131900  1.000000 -0.081163    0.200988\n",
       "Age             0.034212 -0.064910 -0.339898 -0.081163  1.000000   -0.245619\n",
       "FamilySize     -0.040143  0.016639  0.065997  0.200988 -0.245619    1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
